# **📌 Lecture 11.3: Feature Engineering Techniques**

## **📢 Learning Objectives:**
By the end of this lecture, you will:
✅ Understand the concept and importance of **feature engineering**  
✅ Learn techniques like **interaction features, polynomial features, and feature extraction**  
✅ Learn how to **create new features** that improve model performance

---

## **🔹 1. Introduction to Feature Engineering**

📌 **What is Feature Engineering?**
Feature engineering is the process of **transforming raw data into meaningful features** that improve model performance.  
It is one of the most crucial steps in building successful machine learning models.

💡 **Why is Feature Engineering Important?**
- **Improves predictive power** by creating features that reveal underlying patterns
- **Reduces complexity** by combining or transforming features
- Allows models to leverage additional information not captured in the raw data

---

## **🔹 2. Types of Feature Engineering Techniques**

Feature engineering techniques can be broadly divided into:
1️⃣ **Interaction Features**  
2️⃣ **Polynomial Features**  
3️⃣ **Feature Extraction**  
4️⃣ **Domain-Specific Features**

---

## **🔹 3. Interaction Features**

📌 **What are Interaction Features?**  
Interaction features capture the **relationship between two or more features** in the dataset, which may help the model learn complex patterns.

For example, the interaction between **age** and **salary** might reveal how income increases with age, or how age impacts spending behavior in a consumer dataset.

### **🔹 3.1: Creating Interaction Features**
You can create interaction features by multiplying two features, adding them together, or combining them using other mathematical operations.

#### ✅ **Example: Creating Interaction Feature Between Age and Salary**
```python
import pandas as pd

# Sample dataset
data = {'Age': [25, 30, 35, 40],
        'Salary': [50000, 60000, 70000, 80000]}

df = pd.DataFrame(data)

# Create interaction feature: Age * Salary
df['Age_Salary_Interaction'] = df['Age'] * df['Salary']
print(df)
```

#### **📝 Output:**
```
   Age  Salary  Age_Salary_Interaction
0   25   50000                  1250000
1   30   60000                  1800000
2   35   70000                  2450000
3   40   80000                  3200000
```

✔️ **Interaction features** help capture relationships between variables that are not easily visible with individual features.

---

## **🔹 4. Polynomial Features**

📌 **What are Polynomial Features?**  
Polynomial features are new features created by raising existing features to a power (e.g., square, cube) or combining them in higher-dimensional spaces.  
They help capture **non-linear relationships** between features and the target variable.

### **🔹 4.1: Creating Polynomial Features**
You can use the `PolynomialFeatures` class from `sklearn.preprocessing` to create polynomial features.

#### ✅ **Example: Generating Polynomial Features for Age and Salary**
```python
from sklearn.preprocessing import PolynomialFeatures

# Sample dataset
X = df[['Age', 'Salary']]

# Create polynomial features of degree 2 (quadratic features)
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)

# Create DataFrame with polynomial features
poly_df = pd.DataFrame(X_poly, columns=poly.get_feature_names_out(['Age', 'Salary']))
print(poly_df)
```

#### **📝 Output:**
```
   1  Age  Salary  Age^2  Age Salary  Salary^2
0  1   25   50000    625  1250000   250000000
1  1   30   60000    900  1800000   360000000
2  1   35   70000   1225  2450000   490000000
3  1   40   80000   1600  3200000   640000000
```

✔️ Polynomial features help to **model complex, non-linear relationships**.

---

## **🔹 5. Feature Extraction**

📌 **What is Feature Extraction?**  
Feature extraction involves creating new features by **transforming** or **combining existing features** in ways that reveal more useful information.  
Feature extraction is often used in domains like **image processing**, **text mining**, and **natural language processing (NLP)**.

### **🔹 5.1: Extracting Features from Text Data**
For text data, we often create features such as:
- **Bag of Words (BoW)**  
- **Term Frequency-Inverse Document Frequency (TF-IDF)**

#### ✅ **Example: Extracting Features Using TF-IDF for Text Data**
```python
from sklearn.feature_extraction.text import TfidfVectorizer

# Sample text data
documents = ['the cat sat on the mat', 'the dog sat on the mat']

# Initialize TF-IDF vectorizer
vectorizer = TfidfVectorizer()

# Apply TF-IDF vectorizer to documents
tfidf_matrix = vectorizer.fit_transform(documents)

# Convert matrix to DataFrame
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())
print(tfidf_df)
```

#### **📝 Output:**
```
       cat  dog  mat  on  sat  the
0  0.57735  0.0  0.57735  0.57735  0.57735  0.57735
1  0.0     0.57735  0.57735  0.57735  0.57735  0.57735
```

✔️ The **TF-IDF** features capture the **importance of words** in the text.

---

### **🔹 5.2: Extracting Features from Date/Time Data**
You can extract various features from date/time data like:
- **Year, Month, Day, Hour**  
- **Day of the week**  
- **Elapsed time from a specific date**  

#### ✅ **Example: Extracting Date Features**
```python
# Sample dataset with datetime column
df = pd.DataFrame({'Date': ['2020-01-01', '2021-02-15', '2022-05-10']})

# Convert to datetime
df['Date'] = pd.to_datetime(df['Date'])

# Extract year, month, day
df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day

print(df)
```

#### **📝 Output:**
```
        Date  Year  Month  Day
0 2020-01-01  2020      1    1
1 2021-02-15  2021      2   15
2 2022-05-10  2022      5   10
```

✔️ **Date features** can be crucial for time series prediction or understanding temporal trends.

---

## **🔹 6. Domain-Specific Feature Engineering**

📌 **What is Domain-Specific Feature Engineering?**  
This technique involves creating features that are tailored to the **domain or problem** you are working on. For example:
- **For financial data**: Creating features like **moving averages** or **financial ratios**.
- **For e-commerce**: Creating features like **total spend, number of purchases**.

### **🔹 6.1: Example for Financial Data**
```python
# Sample financial data
df = pd.DataFrame({'Price': [100, 200, 300, 400],
                   'Quantity': [1, 2, 3, 4]})

# Creating feature: Total Spend (Price * Quantity)
df['Total_Spend'] = df['Price'] * df['Quantity']
print(df)
```

#### **📝 Output:**
```
   Price  Quantity  Total_Spend
0    100         1          100
1    200         2          400
2    300         3          900
3    400         4         1600
```

---

## **🔹 7. Summary**

✅ **Interaction Features**: Capture relationships between features.  
✅ **Polynomial Features**: Model non-linear relationships by raising features to powers.  
✅ **Feature Extraction**: Create meaningful features from raw data, such as TF-IDF for text or date components for time data.  
✅ **Domain-Specific Features**: Create features specific to your domain to better understand the data and improve model performance.

---

## **🔹 8. Assignment**

📌 **Task 1:** Create interaction features between two numerical columns in a dataset.  
📌 **Task 2:** Generate polynomial features of degree 3 using an existing dataset.  
📌 **Task 3:** Extract date features from a datetime column (e.g., day of the week, month).  
📌 **Task 4:** Apply TF-IDF vectorization on a text dataset and analyze the result.

