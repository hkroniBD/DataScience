### Detailed Lecture on Pandas in Python

---

#### Introduction to Pandas

**Pandas** is a powerful open-source library for data manipulation and analysis in Python. It provides data structures like **Series** (1D) and **DataFrames** (2D) to handle tabular data, time series, and heterogeneous data efficiently. Pandas is widely used for data cleaning, transformation, and analysis in fields like finance, social sciences, and machine learning.

---

#### Key Features of Pandas
![Panda Package](https://github.com/hkroniBD/DataScience/blob/main/assets/Panda%20Package%20Python%20(1).svg)

1. **DataFrame and Series**: Core data structures for handling tabular data.
2. **Data Alignment**: Automatic alignment of data during operations.
3. **Missing Data Handling**: Tools to detect, remove, or fill missing values.
4. **Reshaping and Pivoting**: Flexible reshaping of datasets.
5. **Grouping and Aggregation**: Split-apply-combine operations.
6. **Time Series**: Support for date/time data manipulation.
7. **I/O Tools**: Read/write data from CSV, Excel, SQL, and more.

---

#### Installation

To install Pandas, use pip:

```bash
pip install pandas
```

---

#### Importing Pandas

```python
import pandas as pd
```

---

#### Pandas Data Structures

1. **Series** (1D labeled array):

   ```python
   # Create a Series from a list
   s = pd.Series([10, 20, 30, 40], name="age")
   print(s)
   ```

   **Output**:
   ```
   0    10
   1    20
   2    30
   3    40
   Name: age, dtype: int64
   ```

2. **DataFrame** (2D labeled data structure):

   ```python
   # Create a DataFrame from a dictionary
   data = {
       "name": ["Alice", "Bob", "Charlie"],
       "age": [25, 30, 35],
       "city": ["New York", "London", "Tokyo"]
   }
   df = pd.DataFrame(data)
   print(df)
   ```

   **Output**:
   ```
        name  age      city
   0    Alice   25  New York
   1      Bob   30    London
   2  Charlie   35     Tokyo
   ```

---

#### Reading/Writing Data

1. **Read CSV File**:

   ```python
   # Example: Read a CSV file
   df = pd.read_csv("data.csv")
   print(df.head(2))  # Display first 2 rows
   ```

   **Output** (example):
   ```
      id   name  value
   0   1  Alice    100
   1   2    Bob    200
   ```

2. **Write to CSV**:

   ```python
   df.to_csv("output.csv", index=False)
   ```

---

#### Data Inspection

1. **First/Last Rows**:

   ```python
   print(df.head(2))  # First 2 rows
   print(df.tail(1))  # Last row
   ```

   **Output**:
   ```
        name  age      city
   0    Alice   25  New York
   1      Bob   30    London

        name  age   city
   2  Charlie   35  Tokyo
   ```

2. **Data Types and Missing Values**:

   ```python
   print(df.info())
   ```

   **Output**:
   ```
   <class 'pandas.core.frame.DataFrame'>
   RangeIndex: 3 entries, 0 to 2
   Data columns (total 3 columns):
    #   Column  Non-Null Count  Dtype 
   ---  ------  --------------  ----- 
   0   name    3 non-null      object
   1   age     3 non-null      int64 
   2   city    3 non-null      object
   dtypes: int64(1), object(2)
   ```

3. **Summary Statistics**:

   ```python
   print(df.describe())
   ```

   **Output**:
   ```
              age
   count   3.000000
   mean   30.000000
   std     5.000000
   min    25.000000
   25%    27.500000
   50%    30.000000
   75%    32.500000
   max    35.000000
   ```

---

#### Selection and Indexing

1. **Select Columns**:

   ```python
   print(df["name"])  # Select "name" column
   ```

   **Output**:
   ```
   0      Alice
   1        Bob
   2    Charlie
   Name: name, dtype: object
   ```

2. **Select Rows**:

   ```python
   print(df.iloc[1])  # Select row at index 1
   ```

   **Output**:
   ```
   name      Bob
   age       30
   city    London
   Name: 1, dtype: object
   ```

3. **Filter Rows**:

   ```python
   filtered = df[df["age"] > 25]
   print(filtered)
   ```

   **Output**:
   ```
        name  age    city
   1      Bob   30  London
   2  Charlie   35   Tokyo
   ```

---

#### Data Manipulation

1. **Add a Column**:

   ```python
   df["salary"] = [70000, 80000, 90000]
   print(df)
   ```

   **Output**:
   ```
        name  age      city  salary
   0    Alice   25  New York   70000
   1      Bob   30    London   80000
   2  Charlie   35     Tokyo   90000
   ```

2. **Rename Columns**:

   ```python
   df.rename(columns={"city": "location"}, inplace=True)
   print(df)
   ```

   **Output**:
   ```
        name  age  location  salary
   0    Alice   25  New York   70000
   1      Bob   30    London   80000
   2  Charlie   35     Tokyo   90000
   ```

3. **Apply a Function**:

   ```python
   df["age_plus_5"] = df["age"].apply(lambda x: x + 5)
   print(df)
   ```

   **Output**:
   ```
        name  age  location  salary  age_plus_5
   0    Alice   25  New York   70000          30
   1      Bob   30    London   80000          35
   2  Charlie   35     Tokyo   90000          40
   ```

---

### Handling Missing Data
In real-world datasets, missing values are quite common. **Pandas** offers several methods to detect, remove, or replace missing data efficiently.

Missing values are usually represented as:
- NaN (Not a Number)
- None
First, ensure you have imported Pandas:

```python
import pandas as pd
```

Suppose you have a sample dataset:

```python
data = {
    'Name': ['John', 'Anna', 'Peter', None, 'Linda'],
    'Age': [28, None, 34, 29, None],
    'City': ['New York', 'Paris', None, 'London', 'Berlin']
}

df = pd.DataFrame(data)
print(df)
```

This will produce:

```
    Name   Age      City
0   John  28.0  New York
1   Anna   NaN     Paris
2  Peter  34.0      None
3   None  29.0    London
4  Linda   NaN    Berlin
```

You can see that some values are missing (`None` or `NaN`).

---

## 1. **Detecting Missing Values**

Pandas provides methods to check for missing values:

- `isnull()` — Returns a boolean DataFrame indicating missing values.

```python
print(df.isnull())
```

- `isna()` — Same as `isnull()` (alias).

- To check if **any** value is missing:

```python
print(df.isnull().any())
```

- To check the total number of missing values:

```python
print(df.isnull().sum())
```

---

## 2. **Removing Missing Values**

- **Drop rows with any missing value:**

```python
df_dropped_rows = df.dropna()
print(df_dropped_rows)
```

- **Drop columns with any missing value:**

```python
df_dropped_columns = df.dropna(axis=1)
print(df_dropped_columns)
```

- **Drop only if all values are missing in the row/column:**

```python
df_drop_all_missing = df.dropna(how='all')
```

- **Drop rows where specific column(s) have missing values:**

```python
df_drop_specific = df.dropna(subset=['Name', 'Age'])
print(df_drop_specific)
```

---

## 3. **Filling Missing Values**

Sometimes, instead of removing missing data, you might want to fill it.

- **Fill with a constant value:**

```python
df_filled_constant = df.fillna('Unknown')
print(df_filled_constant)
```

- **Fill with different values per column:**

```python
values = {
    'Name': 'No Name',
    'Age': 0,
    'City': 'No City'
}
df_filled_values = df.fillna(value=values)
print(df_filled_values)
```

- **Forward Fill (propagate last valid observation forward):**

```python
df_forward_fill = df.fillna(method='ffill')
print(df_forward_fill)
```

- **Backward Fill (use next valid observation to fill gap):**

```python
df_backward_fill = df.fillna(method='bfill')
print(df_backward_fill)
```

- **Limit the number of fills:**

```python
df_forward_fill_limited = df.fillna(method='ffill', limit=1)
print(df_forward_fill_limited)
```

---

## 4. **Replacing Missing Values with Statistical Values**

It is common to replace missing values with mean, median, or mode.

- **Fill with mean (for numerical columns):**

```python
mean_age = df['Age'].mean()
df['Age'] = df['Age'].fillna(mean_age)
print(df)
```

- **Fill with median:**

```python
median_age = df['Age'].median()
df['Age'] = df['Age'].fillna(median_age)
print(df)
```

- **Fill with mode (most frequent value):**

```python
mode_city = df['City'].mode()[0]  # mode() returns a Series
df['City'] = df['City'].fillna(mode_city)
print(df)
```

---

## 5. **Interpolating Missing Values**

Pandas can **interpolate** values, which is especially useful for time series or ordered data:

```python
df_interpolated = df.interpolate()
print(df_interpolated)
```

Interpolation can be linear, polynomial, etc.

```python
df_interpolated_poly = df.interpolate(method='polynomial', order=2)
```
*(This requires numeric data and might need some preprocessing.)*

---

## Important Notes:

- `None` and `np.nan` are treated as missing values (`NaN`) by Pandas.
- Use `inplace=True` in methods if you want to modify the DataFrame directly without needing reassignment.

Example:

```python
df.dropna(inplace=True)
```

---

## Summary Table

| Task                              | Method                          |
|-----------------------------------|---------------------------------|
| Detect missing values             | `isnull()`, `isna()`            |
| Remove missing rows               | `dropna()`                     |
| Fill missing with specific value  | `fillna(value)`                |
| Fill with statistical value       | `fillna(df['column'].mean())`   |
| Forward fill                      | `fillna(method='ffill')`        |
| Backward fill                     | `fillna(method='bfill')`        |
| Interpolate missing values        | `interpolate()`                |

---

#### Aggregation and Grouping

1. **GroupBy**:

   ```python
   df_group = pd.DataFrame({
       "department": ["HR", "Tech", "HR", "Tech"],
       "salary": [50000, 80000, 60000, 90000]
   })
   grouped = df_group.groupby("department").mean()
   print(grouped)
   ```

   **Output**:
   ```
             salary
   department       
   HR        55000.0
   Tech      85000.0
   ```

2. **Aggregate Functions**:

   ```python
   print(df_group["salary"].sum())  # Total salary: 280000
   ```

---

#### Merging/Joining DataFrames

1. **Concatenate**:

   ```python
   df1 = pd.DataFrame({"A": [1, 2], "B": [3, 4]})
   df2 = pd.DataFrame({"A": [5, 6], "B": [7, 8]})
   combined = pd.concat([df1, df2], ignore_index=True)
   print(combined)
   ```

   **Output**:
   ```
      A  B
   0  1  3
   1  2  4
   2  5  7
   3  6  8
   ```

2. **Merge**:

   ```python
   left = pd.DataFrame({"key": ["A", "B"], "value": [1, 2]})
   right = pd.DataFrame({"key": ["B", "C"], "value": [3, 4]})
   merged = pd.merge(left, right, on="key", how="left")
   print(merged)
   ```

   **Output**:
   ```
     key  value_x  value_y
   0   A        1      NaN
   1   B        2      3.0
   ```

---

#### Time Series

1. **Date Range**:

   ```python
   dates = pd.date_range("2023-01-01", periods=3)
   df_dates = pd.DataFrame({"date": dates, "sales": [100, 200, 300]})
   print(df_dates)
   ```

   **Output**:
   ```
          date  sales
   0 2023-01-01    100
   1 2023-01-02    200
   2 2023-01-03    300
   ```

2. **Resample Time Series**:

   ```python
   df_dates.set_index("date", inplace=True)
   monthly = df_dates.resample("M").sum()
   print(monthly)
   ```

   **Output**:
   ```
               sales
   date             
   2023-01-31    600
   ```

---

#### Plotting with Pandas

```python
df.plot(x="name", y="salary", kind="bar")
```

**Output**:  
A bar chart showing salaries for Alice, Bob, and Charlie.

---

# Pandas Pivot Table Examples with Outputs

Here are several practical examples with their corresponding outputs to demonstrate pivot tables in action:

## Example 1: Basic Sales Data Analysis
```python
import pandas as pd
import numpy as np

sales_data = {
    'Region': ['East', 'East', 'West', 'West', 'North', 'North'],
    'Product': ['A', 'B', 'A', 'B', 'A', 'B'],
    'Sales': [100, 150, 200, 125, 75, 90],
    'Profit': [20, 30, 40, 25, 15, 18]
}

df = pd.DataFrame(sales_data)

# Basic pivot - average sales by region and product
pivot1 = pd.pivot_table(df, 
                       values='Sales', 
                       index='Region', 
                       columns='Product', 
                       aggfunc='mean')
print("Average Sales by Region and Product:")
print(pivot1)
```

**Output:**
```
Average Sales by Region and Product:
Product      A      B
Region               
East     100.0  150.0
North     75.0   90.0
West     200.0  125.0
```

## Example 2: Multiple Aggregation Functions
```python
# Multiple aggregations for sales and profit
pivot2 = pd.pivot_table(df,
                       values=['Sales', 'Profit'],
                       index='Region',
                       columns='Product',
                       aggfunc={'Sales': [np.mean, np.sum], 
                                'Profit': np.sum})
print("\nMultiple Aggregations:")
print(pivot2)
```

**Output:**
```
Multiple Aggregations:
           Profit       Sales          
Product        A     B   mean    sum   
Region                                 
East          20    30  125.0  250.0
North         15    18   82.5  165.0
West          40    25  162.5  325.0
```

## Example 3: Student Grades Analysis
```python
grades = {
    'Student': ['Alice', 'Bob', 'Charlie', 'Alice', 'Bob', 'Charlie'],
    'Subject': ['Math', 'Math', 'Math', 'Science', 'Science', 'Science'],
    'Grade': [90, 85, 78, 92, 88, 85],
    'Semester': ['Fall', 'Fall', 'Fall', 'Spring', 'Spring', 'Spring']
}

grades_df = pd.DataFrame(grades)

# Pivot with multiple indexes
pivot3 = pd.pivot_table(grades_df,
                       values='Grade',
                       index=['Student', 'Semester'],
                       columns='Subject',
                       aggfunc='mean',
                       fill_value='-')
print("\nStudent Grades by Semester:")
print(pivot3)
```

**Output:**
```
Student Grades by Semester:
Subject             Math Science
Student Semester                
Alice   Fall          90       -
        Spring         -      92
Bob     Fall          85       -
        Spring         -      88
Charlie Fall          78       -
        Spring         -      85
```

## Example 4: Retail Data with Margins
```python
retail = {
    'Date': ['2023-01-01']*4 + ['2023-01-02']*4,
    'Category': ['Electronics', 'Clothing', 'Home', 'Food']*2,
    'Revenue': [5000, 3000, 2000, 1500, 6000, 2500, 1800, 1700],
    'Store': ['NYC', 'NYC', 'LA', 'LA', 'NYC', 'NYC', 'LA', 'LA']
}

retail_df = pd.DataFrame(retail)

# Pivot with totals (margins)
pivot4 = pd.pivot_table(retail_df,
                       values='Revenue',
                       index='Category',
                       columns='Store',
                       aggfunc='sum',
                       margins=True,
                       margins_name='Total')
print("\nRevenue by Category and Store with Totals:")
print(pivot4)
```

**Output:**
```
Revenue by Category and Store with Totals:
Store          LA    NYC   Total
Category                        
Clothing     2500   3000    5500
Electronics  6000   5000   11000
Food         1700   1500    3200
Home         1800   2000    3800
Total       12000  11500   23500
```

## Example 5: Complex Multi-Level Pivot
```python
employees = {
    'Department': ['IT', 'IT', 'HR', 'HR', 'Finance', 'Finance'],
    'Position': ['Junior', 'Senior', 'Junior', 'Senior', 'Junior', 'Senior'],
    'Gender': ['M', 'F', 'F', 'M', 'M', 'F'],
    'Salary': [50000, 80000, 45000, 60000, 55000, 75000],
    'Experience': [2, 5, 1, 4, 3, 6]
}

emp_df = pd.DataFrame(employees)

# Multi-level pivot with custom aggregation
pivot6 = pd.pivot_table(emp_df,
                       values=['Salary', 'Experience'],
                       index=['Department', 'Position'],
                       columns='Gender',
                       aggfunc={'Salary': [np.mean, np.max],
                                'Experience': np.median},
                       fill_value=0)
print("\nComplex Multi-Level Pivot:")
print(pivot6)
```

**Output:**
```
Complex Multi-Level Pivot:
                   Experience       Salary          
Gender                     F    M    mean    amax
Department Position                              
Finance    Junior        0.0  3.0   55000  55000
           Senior        6.0  0.0   75000  75000
HR         Junior        1.0  0.0   45000  45000
           Senior        0.0  4.0   60000  60000
IT         Junior        0.0  2.0   50000  50000
           Senior        5.0  0.0   80000  80000
```

These examples show how pivot tables can transform raw data into meaningful summaries with various aggregation methods and multi-dimensional views. The outputs demonstrate how the data gets reorganized based on the specified index, columns, and aggregation functions.

#### Conclusion

Pandas is the backbone of data manipulation in Python. Its intuitive syntax and powerful tools for data cleaning, transformation, and analysis make it indispensable for data professionals. By mastering Pandas, you can efficiently handle real-world datasets and derive actionable insights.

---

#### Further Reading

- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Python for Data Analysis by Wes McKinney](https://www.oreilly.com/library/view/python-for-data/9781098104023/)
- [Real Python Tutorials](https://realpython.com/learning-paths/pandas-data-science/)

This concludes the detailed lecture on Pandas in Python. Happy analyzing! 📊
